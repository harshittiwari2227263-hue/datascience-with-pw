{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70d013a",
   "metadata": {},
   "source": [
    "# 1. What is Simple Linear Regression?\n",
    "\n",
    "Simple Linear Regression is a statistical method used to model the relationship between one independent variable (X) and one dependent variable (Y) using a straight line.\n",
    "\n",
    "# 2. What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "Linearity, independence of errors, homoscedasticity, normality of errors, and no significant outliers.\n",
    "\n",
    "# 3. What does the coefficient m represent in the equation Y = mX + c?\n",
    "\n",
    "The coefficient m represents the slope, showing how much Y changes for a one-unit increase in X.\n",
    "\n",
    "# 4. What does the intercept c represent in the equation Y = mX + c?\n",
    "\n",
    "The intercept c represents the value of Y when X equals zero.\n",
    "\n",
    "# 5. How do we calculate the slope m in Simple Linear Regression?\n",
    "\n",
    "The slope is calculated as m = Cov(X,Y) / Var(X).\n",
    "\n",
    "# 6. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "\n",
    "It minimizes the sum of squared differences between observed and predicted values.\n",
    "\n",
    "# 7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "\n",
    "R² represents the proportion of variance in Y explained by X.\n",
    "\n",
    "# 8. What is Multiple Linear Regression?\n",
    "\n",
    "Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables.\n",
    "\n",
    "# 9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "\n",
    "Simple regression uses one predictor, while multiple regression uses multiple predictors.\n",
    "\n",
    "# 10. What are the key assumptions of Multiple Linear Regression?\n",
    "\n",
    "Linearity, independence, homoscedasticity, normality of residuals, and no multicollinearity.\n",
    "\n",
    "# 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "\n",
    "Heteroscedasticity occurs when error variance is not constant, leading to unreliable standard errors and hypothesis tests.\n",
    "\n",
    "# 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "\n",
    "Remove correlated variables, use Variance Inflation Factor (VIF), apply regularization, or use dimensionality reduction.\n",
    "\n",
    "# 13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "\n",
    "One-hot encoding, label encoding, and dummy variable creation.\n",
    "\n",
    "# 14. What is the role of interaction terms in Multiple Linear Regression?\n",
    "\n",
    "Interaction terms model the combined effect of two variables on the dependent variable.\n",
    "\n",
    "# 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "\n",
    "In multiple regression, the intercept represents the expected value of Y when all predictors are zero.\n",
    "\n",
    "# 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\n",
    "The slope determines the direction and magnitude of change in Y for changes in predictors.\n",
    "\n",
    "# 17. What are the limitations of using R² as a sole measure of model performance?\n",
    "\n",
    "R² does not indicate causation, can increase with more predictors, and does not measure prediction accuracy.\n",
    "\n",
    "# 18. How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "It indicates high variability and less reliable coefficient estimates.\n",
    "\n",
    "# 19. What is polynomial regression?\n",
    "\n",
    "Polynomial regression models nonlinear relationships by including polynomial terms of the predictor.\n",
    "\n",
    "# 20. When is polynomial regression used?\n",
    "\n",
    "It is used when the relationship between variables is curved rather than linear.\n",
    "\n",
    "# 21. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "\n",
    "It provides a baseline value of Y when predictors are zero.\n",
    "\n",
    "# 22. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\n",
    "It appears as a funnel-shaped pattern in residual plots and affects inference accuracy.\n",
    "\n",
    "# 23. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "\n",
    "It suggests unnecessary predictors that do not improve the model significantly.\n",
    "\n",
    "# 24. Why is it important to scale variables in Multiple Linear Regression?\n",
    "\n",
    "Scaling ensures variables are comparable and improves numerical stability.\n",
    "\n",
    "# 25. How does polynomial regression differ from linear regression?\n",
    "\n",
    "Polynomial regression models curved relationships, while linear regression models straight-line relationships.\n",
    "\n",
    "# 26. What is the general equation for polynomial regression?\n",
    "\n",
    "Y = b0 + b1X + b2X² + ... + bnXⁿ.\n",
    "\n",
    "# 27. Can polynomial regression be applied to multiple variables?\n",
    "\n",
    "Yes, polynomial terms can be applied to multiple predictors.\n",
    "\n",
    "# 28. What are the limitations of polynomial regression?\n",
    "\n",
    "Overfitting, sensitivity to outliers, and poor extrapolation outside data range.\n",
    "\n",
    "# 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\n",
    "Cross-validation, adjusted R², AIC, BIC, and residual analysis.\n",
    "\n",
    "# 30. Why is visualization important in polynomial regression?\n",
    "\n",
    "It helps understand the curve fit and detect overfitting.\n",
    "\n",
    "# 31. How is polynomial regression implemented in Python?\n",
    "\n",
    "It is implemented using libraries like scikit-learn by transforming features with PolynomialFeatures and fitting a LinearRegression model?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
